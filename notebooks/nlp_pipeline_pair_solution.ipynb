{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an NLP Pipeline Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pair problem today, you're going to work on building a class that vectorizes an arbitrary list of documents. The goal is to build something that takes in a bunch of text, and can spit out the cleaned text as a matrix. I'll get you started with a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:13:54.921112Z",
     "start_time": "2018-08-13T13:13:54.918145Z"
    }
   },
   "outputs": [],
   "source": [
    "class NLPPipe:\n",
    "    \n",
    "    def __init__(self, vectorizer, cleaning_function, tokenizer, stemmer):\n",
    "        '''\n",
    "        Create a pipeline that vectorizes an arbitary list of documents.\n",
    "        '''\n",
    "        self.vectorizer = vectorizer\n",
    "        self.cleaning_function = cleaning_function\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "    \n",
    "    def fit(self, text):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Functions (Example)\n",
    "As a quick note, if you want to pass a function into a class you can do so like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:15:31.601377Z",
     "start_time": "2018-08-13T13:15:31.597856Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_the_word_bob_three_times():\n",
    "    for i in range(3):\n",
    "        print('bob')\n",
    "        \n",
    "# Notice the \"Camel Case\" used in class names\n",
    "class ThisIsAnExample:\n",
    "    \n",
    "    def __init__(self, function_input):\n",
    "        # Here, we save an arbitrary function, `function_input` to the object `function_to_run`\n",
    "        self.function_to_run = function_input\n",
    "        \n",
    "    def do_the_thing(self):\n",
    "        self.function_to_run()  # Notice the parethesis, to actually call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:15:46.464728Z",
     "start_time": "2018-08-13T13:15:46.461852Z"
    }
   },
   "outputs": [],
   "source": [
    "example = ThisIsAnExample(print_the_word_bob_three_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, above, that when we put the function in, we **do not invoke it with the parentheses**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:15:51.402550Z",
     "start_time": "2018-08-13T13:15:51.399058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bob\n",
      "bob\n",
      "bob\n"
     ]
    }
   ],
   "source": [
    "example.do_the_thing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of Operations\n",
    "\n",
    "Both the `.fit` and `.transform` methods should take in in *raw* `text` (a *list* of text documents), cleaning them, and then vectorizing them. So, in your `cleaning_function`, we\n",
    "\n",
    "1. Loop through each document in `text` ... and,\n",
    "2. Pick out the individual words using your `tokenizer`\n",
    "3. Capture only the \"meaningful\" portion of each of these words using your `stemmer`\n",
    "4. Join the clean words (stemmed tokens) together, back into each document\n",
    "5. ... Output all the text as another list of (clean) documents, to give to the `vectorizer`\n",
    "\n",
    "`.fit` and `.transform` use the `cleaning_function` before fitting or transforming (respectively) the class's `vectorizer` using the given `text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what I want is the ability to do something like:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "train_corpus = ['BOB the builder', 'He is a strange thing', 'caRtoon type thing', 'Yes, he can fix things']\n",
    "test_corpus = ['BOB the builder', 'can he fix it?', 'yes he can!']  # Note the punctuation ...\n",
    "\n",
    "nlp = nlp_pipe(CountVectorizer(), simple_cleaning_function_i_made, TreebankWordTokenizer(), PorterStemmer())\n",
    "nlp.fit(train_corpus)\n",
    "nlp.transform(test_corpus)\n",
    "```\n",
    "Which should return the test corpus in its vectorizer format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:24:30.903175Z",
     "start_time": "2018-08-13T13:24:30.893116Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "\n",
    "class NLPPipe:\n",
    "   \n",
    "    def __init__(self, vectorizer=CountVectorizer(), tokenizer=None, cleaning_function=None, \n",
    "                 stemmer=None, model=None):\n",
    "        \"\"\"\n",
    "        A class for pipelining our data in NLP problems. The user provides a series of \n",
    "        tools, and this class manages all of the training, transforming, and modification\n",
    "        of the text data.\n",
    "        ---\n",
    "        Inputs:\n",
    "        vectorizer: the model to use for vectorization of text data\n",
    "        tokenizer: The tokenizer to use, if none defaults to split on spaces\n",
    "        cleaning_function: how to clean the data, if None, defaults to the in built class\n",
    "        \"\"\"\n",
    "        if not tokenizer:\n",
    "            tokenizer = self.splitter\n",
    "        if not cleaning_function:\n",
    "            cleaning_function = self.clean_text\n",
    "        self.stemmer = stemmer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.cleaning_function = cleaning_function\n",
    "        self.vectorizer = vectorizer\n",
    "        self._is_fit = False\n",
    "        \n",
    "    def splitter(self, text):\n",
    "        \"\"\"\n",
    "        Default tokenizer that splits on spaces naively\n",
    "        \"\"\"\n",
    "        return text.split(' ')\n",
    "        \n",
    "    def clean_text(self, text, tokenizer, stemmer):\n",
    "        \"\"\"\n",
    "        A naive function to lowercase all works can clean them quickly.\n",
    "        This is the default behavior if no other cleaning function is specified\n",
    "        \"\"\"\n",
    "        cleaned_text = []\n",
    "        for post in text:\n",
    "            cleaned_words = []\n",
    "            for word in tokenizer(post):\n",
    "                low_word = word.lower()\n",
    "                if stemmer:\n",
    "                    low_word = stemmer.stem(low_word)\n",
    "                cleaned_words.append(low_word)\n",
    "            cleaned_text.append(' '.join(cleaned_words))\n",
    "        return cleaned_text\n",
    "    \n",
    "    def fit(self, text):\n",
    "        \"\"\"\n",
    "        Cleans the data and then fits the vectorizer with\n",
    "        the user provided text\n",
    "        \"\"\"\n",
    "        clean_text = self.cleaning_function(text, self.tokenizer, self.stemmer)\n",
    "        self.vectorizer.fit(clean_text)\n",
    "        self._is_fit = True\n",
    "        \n",
    "    def transform(self, text):\n",
    "        \"\"\"\n",
    "        Cleans any provided data and then transforms the data into\n",
    "        a vectorized format based on the fit function. Returns the\n",
    "        vectorized form of the data.\n",
    "        \"\"\"\n",
    "        if not self._is_fit:\n",
    "            raise ValueError(\"Must fit the models before transforming!\")\n",
    "        clean_text = self.cleaning_function(text, self.tokenizer, self.stemmer)\n",
    "        return self.vectorizer.transform(clean_text)\n",
    "    \n",
    "    def save_pipe(self, filename):\n",
    "        \"\"\"\n",
    "        Writes the attributes of the pipeline to a file\n",
    "        allowing a pipeline to be loaded later with the\n",
    "        pre-trained pieces in place.\n",
    "        \"\"\"\n",
    "        if type(filename) != str:\n",
    "            raise TypeError(\"filename must be a string\")\n",
    "        pickle.dump(self.__dict__, open(filename+\".mdl\", 'wb'))\n",
    "        \n",
    "    def load_pipe(self, filename):\n",
    "        \"\"\"\n",
    "        Writes the attributes of the pipeline to a file\n",
    "        allowing a pipeline to be loaded later with the\n",
    "        pre-trained pieces in place.\n",
    "        \"\"\"\n",
    "        if type(filename) != str:\n",
    "            raise TypeError(\"filename must be a string\")\n",
    "        if filename[-4:] != '.mdl':\n",
    "            filename += '.mdl'\n",
    "        self.__dict__ = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:31:22.431182Z",
     "start_time": "2018-08-13T13:31:22.427759Z"
    }
   },
   "outputs": [],
   "source": [
    "train_corpus = ['BOB the builder', 'He is a strange thing', 'caRtoon type thing', 'Yes, he can fix things']\n",
    "test_corpus = ['BOB the builder', 'can he fix it?', 'yes he can!']  # Note the punctuation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:33:06.286865Z",
     "start_time": "2018-08-13T13:33:06.282091Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_cleaning_function_i_made(text, tokenizer, stemmer):\n",
    "    cleaned_text = []\n",
    "    for post in text:\n",
    "        cleaned_words = []\n",
    "        for word in tokenizer(post):\n",
    "            low_word = word.lower()\n",
    "            if stemmer:\n",
    "                low_word = stemmer.stem(low_word)\n",
    "            cleaned_words.append(low_word)\n",
    "        cleaned_text.append(' '.join(cleaned_words))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T13:33:11.089726Z",
     "start_time": "2018-08-13T13:33:11.079610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nlp = NLPPipe(vectorizer=CountVectorizer(), \n",
    "              cleaning_function=simple_cleaning_function_i_made, \n",
    "              tokenizer=TreebankWordTokenizer().tokenize, \n",
    "              stemmer=PorterStemmer())\n",
    "\n",
    "nlp.fit(train_corpus)\n",
    "nlp.transform(test_corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bob': 0,\n",
       " 'the': 8,\n",
       " 'builder': 1,\n",
       " 'he': 5,\n",
       " 'is': 6,\n",
       " 'strang': 7,\n",
       " 'thing': 9,\n",
       " 'cartoon': 3,\n",
       " 'type': 10,\n",
       " 'ye': 11,\n",
       " 'can': 2,\n",
       " 'fix': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stemmer', 'tokenizer', 'model', 'cleaning_function', 'vectorizer', '_is_fit'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Recommendations\n",
    "1. **Your model class should not save data** for many reasons. For one, saving data with your model makes dump/load time very slow, and it also makes it difficult to generalize your model to different data sets.\n",
    "\n",
    "2. Include print statements (or, even better, [logging](https://docs.python.org/3.8/library/logging.html) outputs) wherever you can to make things easier to debug when things go wrong.\n",
    "\n",
    "3. **Keep functions small!!**. I can't stress this enough. The larger the function length (i.e., number of lines) the harder it is to debug and to keep track of what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
